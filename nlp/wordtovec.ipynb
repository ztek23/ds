{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Zacharia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Zacharia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Download required resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over \n",
    "               the world have come and invaded us, captured our lands, conquered our minds. \n",
    "               From Alexander onwards, the Greeks, the Turks, the Moguls, the Portuguese, the British,\n",
    "               the French, the Dutch, all of them came and looted us, took over what was ours. \n",
    "               Yet we have not done this to any other nation. We have not conquered anyone. \n",
    "               We have not grabbed their land, their culture, \n",
    "               their history and tried to enforce our way of life on them. \n",
    "               Why? Because we respect the freedom of others. That is why my \n",
    "               first vision is that of freedom. I believe that India got its first vision of \n",
    "               this in 1857, when we started the War of Independence. It is this freedom that\n",
    "               we must protect and nurture and build on. If we are not free, no one will respect us.\n",
    "               My second vision for India’s development. For fifty years we have been a developing nation.\n",
    "               It is time we see ourselves as a developed nation. We are among the top 5 nations of the world\n",
    "               in terms of GDP. We have a 10 percent growth rate in most areas. Our poverty levels are falling.\n",
    "               Our achievements are being globally recognised today. Yet we lack the self-confidence to\n",
    "               see ourselves as a developed nation, self-reliant and self-assured. Isn’t this incorrect?\n",
    "               I have a third vision. India must stand up to the world. Because I believe that unless India \n",
    "               stands up to the world, no one will respect us. Only strength respects strength. We must be \n",
    "               strong not only as a military power but also as an economic power. Both must go hand-in-hand. \n",
    "               My good fortune was to have worked with three great minds. Dr. Vikram Sarabhai of the Dept. of \n",
    "               space, Professor Satish Dhawan, who succeeded him and Dr. Brahm Prakash, father of nuclear material.\n",
    "               I was lucky to have worked with all three of them closely and consider this the great opportunity of my life. \n",
    "               I see four milestones in my career\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the text\n",
    "text = re.sub(r'\\[[0-9]*\\]', ' ', paragraph)  # Remove numbers in brackets\n",
    "text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "text = text.lower()  # Convert to lowercase\n",
    "text = re.sub(r'\\d', ' ', text)  # Remove numeric values\n",
    "text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing sentences and words\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "sentences = [nltk.word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentences = [[word for word in sentence if word not in stop_words] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Word2Vec model\n",
    "model = Word2Vec(filtered_sentences, vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words in vocabulary\n",
    "words = model.wv.index_to_key  # Updated way to access words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'war':\n",
      " [-0.00219316 -0.00972684  0.00932346  0.00205214 -0.00116468 -0.00556038\n",
      " -0.00849498 -0.00984374  0.00893416 -0.00254779  0.00459008 -0.00457393\n",
      "  0.0099239   0.00369316  0.00103994 -0.00403733  0.00123137 -0.00264427\n",
      "  0.00732724  0.00440273  0.00102987  0.00347164  0.00375799 -0.00685554\n",
      "  0.00895359  0.0017409  -0.00580805  0.00871127 -0.00130675  0.00818783\n",
      " -0.00149107  0.0069821   0.00276787 -0.00438747 -0.00375207  0.00920054\n",
      "  0.00160841 -0.00605008  0.00034056 -0.00197793  0.00160112 -0.00772969\n",
      "  0.00735114  0.00129322  0.00792177  0.00443021 -0.00443056  0.00377498\n",
      " -0.00061726 -0.0098239   0.00826408  0.00960851  0.00967891 -0.00380058\n",
      " -0.00845588  0.00486627 -0.00766062  0.00854968  0.00272571  0.00562201\n",
      "  0.00611192  0.00045927 -0.00210459  0.00075649  0.00982127 -0.00707174\n",
      " -0.0015415  -0.00229067  0.00485779  0.00650814 -0.00416591  0.00363113\n",
      " -0.00446053  0.00327005  0.00819601  0.00362596 -0.00454245 -0.00301966\n",
      "  0.00787969  0.00957807  0.00578929 -0.00325128 -0.00186696 -0.00622714\n",
      " -0.00431587  0.00339159 -0.00645698 -0.00664047  0.00814703  0.00951027\n",
      "  0.00816977  0.00150339 -0.0088157  -0.00759689  0.00161301 -0.00949156\n",
      " -0.00744626  0.00202985 -0.00289303 -0.00915744]\n"
     ]
    }
   ],
   "source": [
    "# Finding word vectors (ensure word exists before accessing)\n",
    "if 'war' in words:\n",
    "    vector = model.wv['war']\n",
    "    print(\"Vector for 'war':\\n\", vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to 'vikram':\n",
      " [('visions', 0.1809452474117279), ('growth', 0.16672933101654053), ('one', 0.1646042913198471), ('took', 0.16457173228263855), (',', 0.1613875925540924), ('developing', 0.14761416614055634), ('fifty', 0.14757291972637177), ('development', 0.13833847641944885), ('worked', 0.13765351474285126), ('time', 0.13316109776496887)]\n"
     ]
    }
   ],
   "source": [
    "# Finding most similar words (ensure word exists before querying)\n",
    "if 'vikram' in words:\n",
    "    similar = model.wv.most_similar('vikram')\n",
    "    print(\"Most similar words to 'vikram':\\n\", similar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
